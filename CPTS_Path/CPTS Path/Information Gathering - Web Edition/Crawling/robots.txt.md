- It acts as a virtual "`etiquette guide`" for bots, outlining which areas of a website they are **allowed to access and which are off-limits.**
- ![[Pasted image 20250621060432.png]]

# Understanding robots.txt Structure
---
1. `User-agent`: This line specifies which crawler or bot the following rules apply to. **A wildcard (`*`) indicates that the rules apply to all bots.** Specific user agents can also be targeted, such as "Googlebot" (Google's crawler) or "Bingbot" (Microsoft's crawler).
2. `Directives`: These lines provide specific instructions to the identified user-agent.
3. ![[Pasted image 20250621060534.png]]